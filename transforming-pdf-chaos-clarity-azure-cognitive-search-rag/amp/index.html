<!DOCTYPE html>
<html âš¡>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">

    <title>Transforming PDF Chaos into clarity: Add PDF Insights with Azure AI Search &amp; RAG</title>

    <link rel="icon" href="https://blog.bart.je/content/images/size/w256h256/2024/05/favicon-194x194.png" type="image/png">
    <link rel="canonical" href="https://blog.bart.je/transforming-pdf-chaos-clarity-azure-cognitive-search-rag/">
    <meta name="referrer" content="no-referrer-when-downgrade">
    
    <meta property="og:site_name" content="Bart Jansen">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Transforming PDF Chaos into clarity: Add PDF Insights with Azure AI Search &amp; RAG">
    <meta property="og:description" content="A great way to add insights to your unstructured PDFs is by ingesting them into an Azure AI Search Index and adding an LLM on top, also known as the RAG pattern as described in: Enhancing Your Data with Azure: Unlocking Insights through Retrieval-Augmented Generation.

This blog posts shows various">
    <meta property="og:url" content="https://blog.bart.je/transforming-pdf-chaos-clarity-azure-cognitive-search-rag/">
    <meta property="og:image" content="https://blog.bart.je/content/images/2021/07/newprofilepic-1.png">
    <meta property="article:published_time" content="2023-11-13T13:52:00.000Z">
    <meta property="article:modified_time" content="2024-06-14T10:29:07.000Z">
    <meta property="article:tag" content="ingestion">
    <meta property="article:tag" content="rag">
    <meta property="article:tag" content="retrievel augmented generation">
    <meta property="article:tag" content="azure cognitive search">
    <meta property="article:tag" content="form recognizer">
    <meta property="article:tag" content="python">
    <meta property="article:tag" content="search index">
    <meta property="article:tag" content="azure openai">
    <meta property="article:tag" content="embeddings">
    <meta property="article:tag" content="azure ai search">
    
    <meta property="article:publisher" content="https://www.facebook.com/bartj">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Transforming PDF Chaos into clarity: Add PDF Insights with Azure AI Search &amp; RAG">
    <meta name="twitter:description" content="A great way to add insights to your unstructured PDFs is by ingesting them into an Azure AI Search Index and adding an LLM on top, also known as the RAG pattern as described in: Enhancing Your Data with Azure: Unlocking Insights through Retrieval-Augmented Generation.

This blog posts shows various">
    <meta name="twitter:url" content="https://blog.bart.je/transforming-pdf-chaos-clarity-azure-cognitive-search-rag/">
    <meta name="twitter:image" content="https://blog.bart.je/content/images/2021/07/newprofilepic.png">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Bart Jansen">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="ingestion, rag, retrievel augmented generation, azure cognitive search, form recognizer, python, search index, azure openai, embeddings, azure ai search">
    <meta name="twitter:site" content="@bartjansn">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="1200">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Bart Jansen",
        "url": "https://blog.bart.je/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://blog.bart.je/content/images/2024/05/profilepictest.jpg",
            "width": 60,
            "height": 60
        }
    },
    "author": {
        "@type": "Person",
        "name": "Bart Jansen",
        "url": "https://blog.bart.je/author/bart/",
        "sameAs": []
    },
    "headline": "Transforming PDF Chaos into clarity: Add PDF Insights with Azure AI Search &amp; RAG",
    "url": "https://blog.bart.je/transforming-pdf-chaos-clarity-azure-cognitive-search-rag/",
    "datePublished": "2023-11-13T13:52:00.000Z",
    "dateModified": "2024-06-14T10:29:07.000Z",
    "keywords": "ingestion, rag, retrievel augmented generation, azure cognitive search, form recognizer, python, search index, azure openai, embeddings, azure ai search",
    "description": "A great way to add insights to your unstructured PDFs is by ingesting them into an Azure AI Search Index and adding an LLM on top, also known as the RAG pattern as described in: Enhancing Your Data with Azure: Unlocking Insights through Retrieval-Augmented Generation.\n\nThis blog posts shows various code snippets, on how to achieve these different steps using Python. The first bit is to setup and populate the Search Index, and the last sections show how to query the search index and enrich the da",
    "mainEntityOfPage": "https://blog.bart.je/transforming-pdf-chaos-clarity-azure-cognitive-search-rag/"
}
    </script>

    <meta name="generator" content="Ghost 5.85">
    <link rel="alternate" type="application/rss+xml" title="Bart Jansen" href="https://blog.bart.je/rss/">

    <style amp-custom>
    *,
    *::before,
    *::after {
        box-sizing: border-box;
    }

    html {
        overflow-x: hidden;
        overflow-y: scroll;
        font-size: 62.5%;
        -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
    }

    body {
        min-height: 100vh;
        margin: 0;
        padding: 0;
        color: #3a4145;
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,sans-serif;
        font-size: 1.7rem;
        line-height: 1.55em;
        font-weight: 400;
        font-style: normal;
        background: #fff;
        scroll-behavior: smooth;
        overflow-x: hidden;
        -webkit-font-smoothing: antialiased;
        -moz-osx-font-smoothing: grayscale;
    }

    p,
    ul,
    ol,
    li,
    dl,
    dd,
    hr,
    pre,
    form,
    table,
    video,
    figure,
    figcaption,
    blockquote {
        margin: 0;
        padding: 0;
    }

    ul[class],
    ol[class] {
        padding: 0;
        list-style: none;
    }

    img {
        display: block;
        max-width: 100%;
    }

    input,
    button,
    select,
    textarea {
        font: inherit;
        -webkit-appearance: none;
    }

    fieldset {
        margin: 0;
        padding: 0;
        border: 0;
    }

    label {
        display: block;
        font-size: 0.9em;
        font-weight: 700;
    }

    hr {
        position: relative;
        display: block;
        width: 100%;
        height: 1px;
        border: 0;
        border-top: 1px solid currentcolor;
        opacity: 0.1;
    }

    ::selection {
        text-shadow: none;
        background: #cbeafb;
    }

    mark {
        background-color: #fdffb6;
    }

    small {
        font-size: 80%;
    }

    sub,
    sup {
        position: relative;
        font-size: 75%;
        line-height: 0;
        vertical-align: baseline;
    }
    sup {
        top: -0.5em;
    }
    sub {
        bottom: -0.25em;
    }

    ul li + li {
        margin-top: 0.6em;
    }

    a {
        color: var(--ghost-accent-color, #1292EE);
        text-decoration-skip-ink: auto;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
        margin: 0;
        font-weight: 700;
        color: #121212;
        line-height: 1.4em;
    }

    h1 {
        font-size: 3.4rem;
        line-height: 1.1em;
    }

    h2 {
        font-size: 2.4rem;
        line-height: 1.2em;
    }

    h3 {
        font-size: 1.8rem;
    }

    h4 {
        font-size: 1.7rem;
    }

    h5 {
        font-size: 1.6rem;
    }

    h6 {
        font-size: 1.6rem;
    }

    amp-img {
        height: 100%;
        width: 100%;
        max-width: 100%;
        max-height: 100%;
    }

    amp-img img {
        object-fit: cover;
    }
    
    amp-youtube {
        height: calc(100vw / 1.78);
        width: 100vw;
        position: relative;
    }

    amp-youtube img {
        position: absolute;
    }

    .page-header {
        padding: 50px 5vmin 30px;
        text-align: center;
        font-size: 2rem;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }

    .page-header a {
        color: #121212;
        font-weight: 700;
        text-decoration: none;
        font-size: 1.6rem;
        letter-spacing: -0.1px;
    }

    .post {
        max-width: 680px;
        margin: 0 auto;
    }

    .post-header {
        margin: 0 5vmin 5vmin;
        text-align: center;
    }

    .post-meta {
        margin: 1rem 0 0 0;
        text-transform: uppercase;
        color: #738a94;
        font-weight: 500;
        font-size: 1.3rem;
    }

    .post-image {
        margin: 0 0 5vmin;
    }

    .post-image img {
        display: block;
        width: 100%;
        height: auto;
    }

    .post-content {
        padding: 0 5vmin;
    }

    .post-content > * + * {
        margin-top: 1.5em;
    }

    .post-content [id]:not(:first-child) {
        margin: 2em 0 0;
    }

    .post-content > [id] + * {
        margin-top: 1rem;
    }

    .post-content [id] + .kg-card,
    .post-content blockquote + .kg-card {
        margin-top: 40px;
    }

    .post-content > ul,
    .post-content > ol,
    .post-content > dl {
        padding-left: 1.9em;
    }

    .post-content hr {
        margin-top: 40px;
    }

    .post .post-content hr + * {
        margin-top: 40px;
    }

    .post-content amp-img {
        background-color: #f8f8f8;
    }

    .post-content blockquote {
        position: relative;
        font-style: italic;
    }

    .post-content blockquote::before {
        content: "";
        position: absolute;
        left: -1.5em;
        top: 0;
        bottom: 0;
        width: 0.3rem;
        background: var(--ghost-accent-color, #1292EE);
    }

    .post-content blockquote.kg-blockquote-alt {
        font-size: 1.2em;
        font-style: italic;
        line-height: 1.6em;
        text-align: center;
        color: #738a94;
        padding: 0.75em 3em 1.25em;
    }

    .post-content blockquote.kg-blockquote-alt::before {
        display: none;
    }

    .post-content :not(.kg-card):not([id]) + .kg-card {
        margin-top: 40px;
    }

    .post-content .kg-card + :not(.kg-card) {
        margin-top: 40px;
    }

    .kg-card figcaption {
        padding: 1.5rem 1.5rem 0;
        text-align: center;
        font-weight: 500;
        font-size: 1.3rem;
        line-height: 1.4em;
        opacity: 0.6;
    }

    .kg-card figcaption strong {
        color: rgba(0,0,0,0.8);
    }

    .post-content :not(pre) code {
        vertical-align: middle;
        padding: 0.15em 0.4em 0.15em;
        border: #e1eaef 1px solid;
        font-weight: 400;
        font-size: 0.9em;
        line-height: 1em;
        color: #15171a;
        background: #f0f6f9;
        border-radius: 0.25em;
    }

    .post-content > pre {
        overflow: scroll;
        padding: 16px 20px;
        color: #fff;
        background: #1F2428;
        border-radius: 5px;
        box-shadow: 0 2px 6px -2px rgba(0,0,0,.1), 0 0 1px rgba(0,0,0,.4);
    }

    .kg-embed-card {
        display: flex;
        flex-direction: column;
        align-items: center;
        width: 100%;
    }

    .kg-image-card img {
        margin: auto;
    }

    .kg-gallery-card + .kg-gallery-card {
        margin-top: 0.75em;
    }

    .kg-gallery-container {
        position: relative;
    }

    .kg-gallery-row {
        display: flex;
        flex-direction: row;
        justify-content: center;
    }

    .kg-gallery-image {
        width: 100%;
        height: 100%;
    }

    .kg-gallery-row:not(:first-of-type) {
        margin: 0.75em 0 0 0;
    }

    .kg-gallery-image:not(:first-of-type) {
        margin: 0 0 0 0.75em;
    }

    .kg-bookmark-card,
    .kg-bookmark-publisher {
        position: relative;
    }

    .kg-bookmark-container,
    .kg-bookmark-container:hover {
        display: flex;
        flex-wrap: wrap;
        flex-direction: row-reverse;
        color: currentColor;
        background: rgba(255,255,255,0.6);
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,sans-serif;
        text-decoration: none;
        border-radius: 3px;
        box-shadow: 0 2px 6px -2px rgba(0, 0, 0, 0.1), 0 0 1px rgba(0, 0, 0, 0.4);
        overflow: hidden;
    }

    .kg-bookmark-content {
        flex-basis: 0;
        flex-grow: 999;
        padding: 20px;
        order: 1;
    }

    .kg-bookmark-title {
        font-weight: 600;
        font-size: 1.5rem;
        line-height: 1.3em;
    }

    .kg-bookmark-description {
        display: -webkit-box;
        max-height: 45px;
        margin: 0.5em 0 0 0;
        font-size: 1.4rem;
        line-height: 1.55em;
        overflow: hidden;
        opacity: 0.8;
        -webkit-line-clamp: 2;
        -webkit-box-orient: vertical;
    }

    .kg-bookmark-metadata {
        margin-top: 20px;
    }

    .kg-bookmark-metadata {
        display: flex;
        align-items: center;
        font-weight: 500;
        font-size: 1.3rem;
        line-height: 1.3em;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }

    .kg-bookmark-description {
        display: -webkit-box;
        -webkit-box-orient: vertical;
        -webkit-line-clamp: 2;
        overflow: hidden;
    }

    .kg-bookmark-metadata amp-img {
        width: 18px;
        height: 18px;
        max-width: 18px;
        max-height: 18px;
        margin-right: 10px;
    }

    .kg-bookmark-thumbnail {
        display: flex;
        flex-basis: 20rem;
        flex-grow: 1;
        justify-content: flex-end;
    }

    .kg-bookmark-thumbnail amp-img {
        max-height: 200px;
    }

    .kg-bookmark-author {
        white-space: nowrap;
        text-overflow: ellipsis;
        overflow: hidden;
    }

    .kg-bookmark-publisher::before {
        content: "â€¢";
        margin: 0 .5em;
    }

    .kg-toggle-card-icon {
        display: none;
    }

    .kg-toggle-content {
        margin-top: 0.8rem;
    }

    .kg-product-card-container {
        background: transparent;
        padding: 20px;
        width: 100%;
        border-radius: 5px;
        box-shadow: inset 0 0 0 1px rgb(124 139 154 / 25%);
    }

    .kg-product-card-description p {
        margin-top: 1.5em;
    }

    .kg-product-card-description ul {
        margin-left: 24px;
    }

    .kg-product-card-title {
        font-size: 1.9rem;
        font-weight: 700;
    }

    .kg-product-card-rating-star {
        height: 28px;
        width: 20px;
        margin-right: 2px;
    }

    .kg-product-card-rating-star svg {
    width: 16px;
    height: 16px;
    fill: currentColor;
    opacity: 0.15;
    }

    .kg-product-card-rating-active.kg-product-card-rating-star svg {
    opacity: 1;
    }

    .kg-nft-card-container {
        position: relative;
        display: flex;
        flex: auto;
        flex-direction: column;
        text-decoration: none;
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,sans-serif;
        font-size: 1.4rem;
        font-weight: 400;
        box-shadow: 0 2px 6px -2px rgb(0 0 0 / 10%), 0 0 1px rgb(0 0 0 / 40%);
        width: 100%;
        max-width: 512px;
        color: #15212A;
        background: #fff;
        border-radius: 5px;
        transition: none;
        margin: 0 auto;
    }

    .kg-nft-metadata {
        padding: 2.0rem;
    }

    .kg-nft-image-container {
        position: relative;
    }

    .kg-nft-image {
        display: flex;
        border-radius: 5px 5px 0 0;
    }

    .kg-nft-header {
        display: flex;
        justify-content: space-between;
        align-items: flex-start;
        gap: 20px;
    }

    .kg-nft-header h4.kg-nft-title {
        font-size: 1.9rem;
        font-weight: 700;
        margin: 0;
        color: #15212A;
    }

    .kg-nft-header amp-img {
        max-width: 114px;
        max-height: 26px;
    }

    .kg-nft-opensea-logo {
        margin-top: 2px;
        width: 100px;
    }

    .kg-nft-creator {
        font-family: inherit;
        color: #95A1AD;
    }

    .kg-nft-creator span {
        font-weight: 500;
        color: #15212A;
    }

    .kg-nft-card p.kg-nft-description {
        font-size: 1.4rem;
        line-height: 1.4em;
        margin: 2.0rem 0 0;
        color: #222;
    }

    .kg-button-card {
        display: flex;
        position: static;
        align-items: center;
        width: 100%;
        justify-content: center;
    }

    .kg-btn {
        display: flex;
        position: static;
        align-items: center;
        padding: 0 2.0rem;
        height: 4.0rem;
        line-height: 4.0rem;
        font-size: 1.65rem;
        font-weight: 600;
        text-decoration: none;
        border-radius: 5px;
        transition: opacity 0.2s ease-in-out;
    }

    .kg-btn:hover {
        opacity: 0.85;
    }

    .kg-btn-accent {
        background-color: var(--ghost-accent-color, #1292EE);
        color: #fff;
    }

    .kg-callout-card {
        display: flex;
        padding: 20px 28px;
        border-radius: 3px;
    }

    .kg-callout-card-grey {
        background: rgba(124, 139, 154, 0.13);
    }

    .kg-callout-card-white {
        background: transparent;
        box-shadow: inset 0 0 0 1px rgba(124, 139, 154, 0.25);
    }

    .kg-callout-card-blue {
        background: rgba(33, 172, 232, 0.12);
    }

    .kg-callout-card-green {
        background: rgba(52, 183, 67, 0.12);
    }

    .kg-callout-card-yellow {
        background: rgba(240, 165, 15, 0.13);
    }

    .kg-callout-card-red {
        background: rgba(209, 46, 46, 0.11);
    }

    .kg-callout-card-pink {
        background: rgba(225, 71, 174, 0.11);
    }

    .kg-callout-card-purple {
        background: rgba(135, 85, 236, 0.12);
    }

    .kg-callout-card-accent {
        background: var(--ghost-accent-color);
        color: #fff;
    }

    .kg-callout-card-accent a {
        color: #fff;
    }

    .kg-callout-emoji {
        padding-right: 16px;
        line-height: 1.3;
        font-size: 1.25em;
    }

    .kg-header-card {
        padding: 6em 3em;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        text-align: center;
    }

    .kg-header-card.kg-size-small {
        padding-top: 4em;
        padding-bottom: 4em;
    }

    .kg-header-card.kg-size-large {
        padding-top: 12em;
        padding-bottom: 12em;
    }

    .kg-header-card.kg-width-full {
        padding-left: 4em;
        padding-right: 4em;
    }

    .kg-header-card.kg-align-left {
        text-align: left;
        align-items: flex-start;
    }

    .kg-header-card.kg-style-dark {
        background: #15171a;
        color: #ffffff;
    }

    .kg-header-card.kg-style-light {
        color: #15171a;
        border: 1px solid rgba(124, 139, 154, 0.25);
        border-width: 1px 0;
    }

    .kg-header-card.kg-style-accent {
        background-color: var(--ghost-accent-color);
    }

    .kg-header-card.kg-style-image {
        background-color: #e7e7eb;
        background-size: cover;
        background-position: center center;
    }

    .kg-header-card h2 {
        font-size: 4em;
        font-weight: 700;
        line-height: 1.1em;
        margin: 0;
    }

    .kg-header-card h2 strong {
        font-weight: 800;
    }

    .kg-header-card.kg-size-small h2 {
        font-size: 3em;
    }

    .kg-header-card.kg-size-large h2 {
        font-size: 5em;
    }

    .kg-header-card h3 {
        font-size: 1.25em;
        font-weight: 500;
        line-height: 1.3em;
        margin: 0;
    }

    .kg-header-card h3 strong {
        font-weight: 600;
    }

    .kg-header-card.kg-size-small h3 {
        font-size: 1em;
    }

    .kg-header-card.kg-size-large h3 {
        font-size: 1.5em;
    }

    .kg-header-card:not(.kg-style-light) h2,
    .kg-header-card:not(.kg-style-light) h3 {
        color: #ffffff;
    }

    .kg-header-card a.kg-header-card-button {
        display: flex;
        position: static;
        align-items: center;
        padding: 0 1.2em;
        height: 2.4em;
        line-height: 1em;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif;
        font-size: 0.95em;
        font-weight: 600;
        text-decoration: none;
        border-radius: 5px;
        transition: opacity 0.2s ease-in-out;
        background-color: var(--ghost-accent-color);
        color: #ffffff;
        margin: 1.75em 0 0;
    }

    .kg-header-card a.kg-header-card-button:hover {
        opacity: 0.85;
    }

    .kg-header-card.kg-size-large a.kg-header-card-button {
        margin-top: 2em;
    }

    .kg-header-card.kg-size-small a.kg-header-card-button {
        margin-top: 1.5em;
    }

    .kg-header-card.kg-style-image a.kg-header-card-button,
    .kg-header-card.kg-style-dark a.kg-header-card-button {
        background: #ffffff;
        color: #15171a;
    }

    .kg-header-card.kg-style-accent a.kg-header-card-button {
        background: #ffffff;
        color: var(--ghost-accent-color);
    }

    .kg-audio-card {
        display: flex;
        width: 100%;
        box-shadow: inset 0 0 0 1px rgba(124, 139, 154, 0.25);
    }

    .kg-audio-thumbnail {
        display: flex;
        justify-content: center;
        align-items: center;
        width: 80px;
        min-width: 80px;
        height: 80px;
        background: transparent;
        object-fit: cover;
        aspect-ratio: 1/1;
        border-radius: 3px 0 0 3px;
    }

    .kg-audio-thumbnail.placeholder {
        background: var(--ghost-accent-color);
    }

    .kg-audio-thumbnail.placeholder svg {
        width: 24px;
        height: 24px;
        fill: white;
    }

    .kg-audio-player-container {
        position: relative;
        display: flex;
        flex-direction: column;
        justify-content: space-between;
        width: 100%;
        --seek-before-width: 0%;
        --volume-before-width: 100%;
        --buffered-width: 0%;
    }

    .kg-audio-title {
        width: 100%;
        padding: 8px 12px 0;
        border: none;
        font-family: inherit;
        font-size: 1.1em;
        font-weight: 700;
        background: transparent;
    }

    .kg-audio-player {
        display: none;
    }

    .kg-width-full.kg-card-hascaption {
        display: grid;
        grid-template-columns: inherit;
    }

    .post-content table {
        border-collapse: collapse;
        width: 100%;
    }

    .post-content th {
        padding: 0.5em 0.8em;
        text-align: left;
        font-size: .75em;
        text-transform: uppercase;
    }

    .post-content td {
        padding: 0.4em 0.7em;
    }

    .post-content tbody tr:nth-child(2n + 1) {
        background-color: rgba(0,0,0,0.1);
        padding: 1px;
    }

    .post-content tbody tr:nth-child(2n + 2) td:last-child {
        box-shadow:
            inset 1px 0 rgba(0,0,0,0.1),
            inset -1px 0 rgba(0,0,0,0.1);
    }

    .post-content tbody tr:nth-child(2n + 2) td {
        box-shadow: inset 1px 0 rgba(0,0,0,0.1);
    }

    .post-content tbody tr:last-child {
        border-bottom: 1px solid rgba(0,0,0,.1);
    }

    .page-footer {
        padding: 60px 5vmin;
        margin: 60px auto 0;
        text-align: center;
        background-color: #f8f8f8;
    }

    .page-footer h3 {
        margin: 0.5rem 0 0 0;
    }

    .page-footer p {
        max-width: 500px;
        margin: 1rem auto 1.5rem;
        font-size: 1.7rem;
        line-height: 1.5em;
        color: rgba(0,0,0,0.6)
    }

    .powered {
        display: inline-flex;
        align-items: center;
        margin: 30px 0 0;
        padding: 6px 9px 6px 6px;
        border: rgba(0,0,0,0.1) 1px solid;
        font-size: 12px;
        line-height: 12px;
        letter-spacing: -0.2px;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif;
        font-weight: 500;
        color: #222;
        text-decoration: none;
        background: #fff;
        border-radius: 6px;
    }

    .powered svg {
        height: 16px;
        width: 16px;
        margin: 0 6px 0 0;
    }

    @media (max-width: 600px) {
        body {
            font-size: 1.6rem;
        }
        h1 {
            font-size: 3rem;
        }

        h2 {
            font-size: 2.2rem;
        }
    }

    @media (max-width: 400px) {
        h1 {
            font-size: 2.6rem;
            line-height: 1.15em;
        }
        h2 {
            font-size: 2rem;
            line-height: 1.2em;
        }
        h3 {
            font-size: 1.7rem;
        }
    }

    :root {--ghost-accent-color: #ecc24a;}
    </style>

    <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
    <script async src="https://cdn.ampproject.org/v0.js"></script>

    

</head>

<body class="amp-template">
    <header class="page-header">
        <a href="https://blog.bart.je">
                <amp-img class="site-icon" src="https://blog.bart.je/content/images/2024/05/favicon-194x194.png" width="50" height="50" layout="fixed" alt="Bart Jansen"></amp-img>
        </a>
    </header>

    <main class="content" role="main">
        <article class="post">

            <header class="post-header">
                <h1 class="post-title">Transforming PDF Chaos into clarity: Add PDF Insights with Azure AI Search &amp; RAG</h1>
                <section class="post-meta">
                    Bart Jansen -
                    <time class="post-date" datetime="2023-11-13">13 Nov 2023</time>
                </section>
            </header>
            <section class="post-content">

                <p>A great way to add insights to your unstructured PDFs is by ingesting them into an Azure AI Search Index and adding an LLM on top, also known as the RAG pattern as described in: <a href="https://blog.bart.je/enhancing-data-azure-insights-retrieval-augmented-generation/?ref=192.168.1.45" rel="noreferrer">Enhancing Your Data with Azure: Unlocking Insights through Retrieval-Augmented Generation</a>.</p><p>This blog posts shows various code snippets, on how to achieve these different steps using Python. The first bit is to setup and populate the Search Index, and the last sections show how to query the search index and enrich the data using GPT. </p><blockquote>Please keep in mind that these snippets are a great starting point, but have been kept as small as possible to fit the format of this blog. Comprehensive processing such as chunking, text splitting, enriching, embedding and semantic configuration, semantic reranking have consciously been kept out of the scope of this blog post, but are required for creating an effective search index.</blockquote><figure class="kg-card kg-image-card kg-width-full"><amp-img src="https://blog.bart.je/content/images/2023/11/cognitive-search-pdf-ingestion.png" class="kg-image" alt="" width="3087" height="752" srcset="https://blog.bart.je/content/images/size/w600/2023/11/cognitive-search-pdf-ingestion.png 600w, https://blog.bart.je/content/images/size/w1000/2023/11/cognitive-search-pdf-ingestion.png 1000w, https://blog.bart.je/content/images/size/w1600/2023/11/cognitive-search-pdf-ingestion.png 1600w, https://blog.bart.je/content/images/size/w2400/2023/11/cognitive-search-pdf-ingestion.png 2400w" layout="responsive"></amp-img></figure><h3 id="create-azure-ai-search-index">Create Azure AI Search Index</h3><p>First step is to create an Azure AI Search Index, this can be done through the Azure Portal, the REST API or with the Python SDK:</p><pre><code class="language-python">SEARCH_SERVICE = "your-azure-search-resource"
SEARCH_INDEX = "your-search-index"
SEARCH_KEY = "your-secret-azure-search-key"
SEARCH_CREDS = AzureKeyCredential(SEARCH_KEY)
SEARCH_CLIENT = SearchIndexerClient(endpoint=f"https://{SEARCH_SERVICE}.search.windows.net/", credential=SEARCH_CREDS)

def create_index():
    client = SearchIndexClient(endpoint=f"https://{SEARCH_SERVICE}.search.windows.net/", index=SEARCH_INDEX, credential=SEARCH_CREDS)
    # Define the index
    index_definition = SearchIndex(
        name=SEARCH_INDEX,
        fields=[
            SearchField(name="id", type=SearchFieldDataType.String, key=True),
            SearchField(name="content", type=SearchFieldDataType.String, filterable=True, sortable=True),
            SearchField(name="sourcefile", type=SearchFieldDataType.String, filterable=True, facetable=True),
            SearchField(
                name="embedding",
                type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
                hidden=False,
                searchable=True,
                filterable=False,
                sortable=False,
                facetable=False,
                vector_search_dimensions=1536,
                vector_search_configuration="default",
            )
        ],
        semantic_settings=SemanticSettings(
            configurations=[
                SemanticConfiguration(
                    name='default',
                    prioritized_fields=PrioritizedFields(
                        title_field=None, prioritized_content_fields=[SemanticField(field_name='content')]
                    )
                )
            ]
        ),
        vector_search=VectorSearch(
            algorithm_configurations=[
                VectorSearchAlgorithmConfiguration(
                    name="default",
                    kind="hnsw",
                    hnsw_parameters=HnswParameters(metric="cosine")
                )
            ]
        )
    )
    
    # Create the index
    client.create_index(index=index_definition)
</code></pre><p>This sets up an Azure AI Search Index with these fields:</p><ul><li> <code>id</code> : ID of the document</li><li> <code>content</code> : plain text content of your document</li><li><code>sourcefile</code> : PDF file used, including page number of this document</li><li><code>embedding</code> : vectorized embedding of your plain text content</li></ul><p>Since we're using a vector embedding field we configure <code>vector_search</code>, we also setup a default <code>semantic_configuration</code> and define which fields to use for our (non-vector) content (<code>content</code> in our case).</p><h3 id="process-pdfs">Process PDFs</h3><p>With the index in place, we need to split PDFs to process, chunk size &amp; overlap size, form recognizer for OCR/Tables, enrichment.</p><p>First, we split the PDFs into single page documents:</p><pre><code class="language-python">import io
from PyPDF2 import PdfFileReader, PdfFileWriter

def split_pdf_to_pages(pdf_path):
    """
    Splits a PDF file into individual pages and returns a list of byte streams, 
    each representing a single page.
    """
    pages = []
    with open(pdf_path, 'rb') as file:
        reader = PdfFileReader(file)

        for i in range(reader.getNumPages()):
            writer = PdfFileWriter()
            writer.addPage(reader.getPage(i))

            page_stream = io.BytesIO()
            writer.write(page_stream)
            page_stream.seek(0)
            pages.append(page_stream)

    return pages

# Example usage
pdf_path = 'path/to/your/pdf/file.pdf'
pages = split_pdf_to_pages(pdf_path)</code></pre><p>We then use the contents of these single-page documents with Azure Form Recognizer (also known as Azure Document Intelligence), to extract the text from the document:</p><pre><code class="language-python">FORM_RECOGNIZER_SERVICE = "your-fr-resource"
FORM_RECOGNIZER_KEY = "SECRET_FR_KEY"
FORM_RECOGNIZER_CREDS = AzureKeyCredential(FORM_RECOGNIZER_KEY)

def get_document_text_from_content(blob_content):
    offset = 0
    page_map = []

    form_recognizer_client = DocumentAnalysisClient(
        endpoint=f"https://{FORM_RECOGNIZER_SERVICE}.cognitiveservices.azure.com/", 
        credential=FORM_RECOGNIZER_CREDS, 
        headers={"x-ms-useragent": "azure-search-sample/1.0.0"}
    )

    poller = form_recognizer_client.begin_analyze_document("prebuilt-layout", document=blob_content)
    form_recognizer_results = poller.result()

    for page_num, page in enumerate(form_recognizer_results.pages):
        # Extract text for each page
        page_text = page.content
        page_map.append((page_num, offset, page_text))
        offset += len(page_text)

    return page_map
</code></pre><h3 id="split-text-into-indexable-sized-chunks">Split text into indexable sized chunks</h3><p>With the page contents extracted from the PDF, per page, we can split the text to chunks, an easy way to do this is:</p><pre><code class="language-python">def split_text(page_map, max_section_length):
    """
    Splits the text from page_map into sections of a specified maximum length.

    :param page_map: List of tuples containing page text.
    :param max_section_length: Maximum length of each text section.
    :return: Generator yielding text sections.
    """
    all_text = "".join(p[2] for p in page_map)  # Concatenate all text
    start = 0
    length = len(all_text)

    while start &lt; length:
        end = min(start + max_section_length, length)
        section_text = all_text[start:end]
        yield section_text
        start = end

# Example usage
max_section_length = 1000  # For example, 1000 characters per section
sections = split_text(page_map, max_section_length)

for section in sections:
    print(section)  # Process each section as needed
</code></pre><blockquote>Note: the snippet above is a very simplistic way of splitting text. In production you'd want to take into account sentence_endings, overlap, word_breaks, tables, cross-page sections, etc.</blockquote><h3 id="create-search-index-sections">Create Search Index sections</h3><p>We can use the <code>page_map</code> from <code>get_document_from_text</code>  to call the<code>split_text</code> function and setup the sections for our index:</p><pre><code class="language-python">def create_sections(filename, page_map):
    for i, (content, pagenum) in enumerate(split_text(page_map, filename)):
        section = {
            "id": f"{filename}-page-{i}",
            "content": content,
            "sourcefile": filename
        }
        section["embedding"] = compute_embedding(content)
        yield section</code></pre><h3 id="generate-embeddings">Generate embeddings</h3><p>We can generate embeddings using Azure OpenAI's <code>text-embedding-ada-002</code> model:</p><pre><code class="language-python"># Configurations
OPENAI_SERVICE = "your-azure-openai-resource"
OPENAI_DEPLOYMENT = "embedding"
OPENAI_KEY = "your-secret-openai-key"

# OpenAI setup
openai.api_type = "azure"
openai.api_key = OPENAI_KEY
openai.api_base = f"https://{OPENAI_SERVICE}.openai.azure.com"
openai.api_version = "2022-12-01"

def compute_embedding(text):
    return openai.Embedding.create(engine=OPENAI_DEPLOYMENT, input=text)["data"][0]["embedding"]</code></pre><h3 id="ingest-data-into-search-index">Ingest Data into Search Index</h3><p>With the computed sections from <code>create_sections</code> we can batch-upload them  (in pairs of 1000 documents) into our Search Index:</p><pre><code class="language-python">def index_sections(filename, sections):
    """
    Indexes sections from a file into a search index.

    :param filename: The name of the file being indexed.
    :param sections: The sections of text to index.
    """
    search_client = SearchClient(endpoint=f"https://{SEARCH_SERVICE}.search.windows.net/",
                                 index_name=SEARCH_INDEX,
                                 credential=SEARCH_CREDS)

    batch = []
    for i, section in enumerate(sections, 1):
        batch.append(section)
        if i % 1000 == 0:
            search_client.upload_documents(documents=batch)
            batch = []

    if batch:
        search_client.upload_documents(documents=batch)

# filename and sections from previous steps
index_sections(filename, sections)</code></pre><p>The result of this last ingestion step is a fully populated Search Index, ready to be consumed.</p><h3 id="retrieval-augmented-generation">Retrieval Augmented Generation</h3><p>Now we can query our Search Index endpoint, using:</p><pre><code class="language-python">from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient

def search_index(query, endpoint, index_name, api_key):
    """
    Searches the indexed data in Azure Search.

    :param query: The search query string.
    :param endpoint: Azure Search service endpoint URL.
    :param index_name: Name of the Azure Search index.
    :param api_key: Azure Search API key.
    :return: Search results.
    """
    credential = AzureKeyCredential(api_key)
    search_client = SearchClient(endpoint=endpoint, index_name=index_name, credential=credential)

    results = search_client.search(query)
    return [result for result in results]

# Example usage
endpoint = 'https://[service-name].search.windows.net'  # Replace with your service endpoint
index_name = 'your-index-name'  # Replace with your index name
api_key = 'your-api-key'  # Replace with your API key
search_query = 'example search text'

search_results = search_index(search_query, endpoint, index_name, api_key)

for result in search_results:
    print(result)  # Process each search result as needed
</code></pre><h3 id="enrich-results-with-gpt-4">Enrich results with GPT-4</h3><p>After retrieval, we can enrich the search results with GPT-4:</p><pre><code class="language-python">import openai

def enrich_with_gpt(result, openai_api_key):
    """
    Enriches the search result with additional information generated by OpenAI GPT-4.

    :param result: The search result item to enrich.
    :param openai_api_key: OpenAI API key.
    :return: Enriched information.
    """
    openai.api_key = openai_api_key

    # Construct a prompt based on the result for GPT-4
    prompt = f"Based on the following search result: {result}, generate additional insights."

    # Call OpenAI GPT-4 to generate additional information
    response = openai.Completion.create(engine="gpt4-32k", prompt=prompt, max_tokens=150)
    return response.choices[0].text.strip()

# Example usage
openai_api_key = 'your-openai-api-key'  # Replace with your OpenAI API key

enriched_results = []
for result in search_results:
    enriched_info = enrich_with_gpt(result, openai_api_key)
    enriched_results.append((result, enriched_info))

for result, enriched_info in enriched_results:
    print("Original Result:", result)
    print("Enriched Information:", enriched_info)
    print("-----")
</code></pre><h3 id="next-steps">Next Steps</h3><p>As mentioned in the beginning of this blog post, this code snippets can serve as the basis of your RAG ingestion &amp; consumption pipeline. But to come increase the effectiveness of your RAG implementation, there's a lot of improvements that can be made.</p><p></p><p></p>

            </section>

        </article>
    </main>
    <footer class="page-footer">
            <amp-img class="site-icon" src="https://blog.bart.je/content/images/2024/05/favicon-194x194.png" width="50" height="50" layout="fixed" alt="Bart Jansen"></amp-img>
        <h3>Bart Jansen</h3>
            <p>Software Engineer at Microsoft</p>
        <p><a href="https://blog.bart.je">Read more posts â†’</a></p>
        <a class="powered" href="https://ghost.org" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 156 156"><g fill="none" fill-rule="evenodd"><rect fill="#15212B" width="156" height="156" rx="27"/><g transform="translate(36 36)" fill="#F6F8FA"><path d="M0 71.007A4.004 4.004 0 014 67h26a4 4 0 014 4.007v8.986A4.004 4.004 0 0130 84H4a4 4 0 01-4-4.007v-8.986zM50 71.007A4.004 4.004 0 0154 67h26a4 4 0 014 4.007v8.986A4.004 4.004 0 0180 84H54a4 4 0 01-4-4.007v-8.986z"/><rect y="34" width="84" height="17" rx="4"/><path d="M0 4.007A4.007 4.007 0 014.007 0h41.986A4.003 4.003 0 0150 4.007v8.986A4.007 4.007 0 0145.993 17H4.007A4.003 4.003 0 010 12.993V4.007z"/><rect x="67" width="17" height="17" rx="4"/></g></g></svg> Published with Ghost</a>
    </footer>
    
</body>
</html>
